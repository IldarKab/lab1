{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9msBf4pEWIK0D37JxVadL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D66pe-Uv0Ehg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision as tv\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZWQVtsPiayV",
        "outputId": "e866a68a-6adf-44b5-a3a9-affeb8564708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset2class(torch.utils.data.Dataset):\n",
        "    def __init__(self, path_dir1, path_dir2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.path_dir1 = path_dir1\n",
        "        self.path_dir2 = path_dir2\n",
        "\n",
        "        self.dir1_list = sorted(os.listdir(path_dir1))\n",
        "        self.dir2_list = sorted(os.listdir(path_dir2))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dir1_list) + len(self.dir2_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        idx = idx % self.__len__()\n",
        "\n",
        "        if idx < len(self.dir1_list):\n",
        "            class_id = 0\n",
        "            img_path = os.path.join(self.path_dir1, self.dir1_list[idx])\n",
        "        else:\n",
        "            class_id = 1\n",
        "            idx -= len(self.dir1_list)\n",
        "            img_path = os.path.join(self.path_dir2, self.dir2_list[idx])\n",
        "\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "        while img is None or img.size == 0:\n",
        "            idx = (idx + 1) % self.__len__()\n",
        "            if idx < len(self.dir1_list):\n",
        "                class_id = 0\n",
        "                img_path = os.path.join(self.path_dir1, self.dir1_list[idx])\n",
        "            else:\n",
        "                class_id = 1\n",
        "                idx -= len(self.dir1_list)\n",
        "                img_path = os.path.join(self.path_dir2, self.dir2_list[idx])\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            if idx == 0:\n",
        "                raise IndexError(\"All images are empty.\")\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = img.astype(np.float32)\n",
        "        img = img / 255.0\n",
        "\n",
        "        img = cv2.resize(img, (50, 50), interpolation=cv2.INTER_AREA)\n",
        "        img = img.transpose((2, 0, 1))\n",
        "        t_img = torch.from_numpy(img)\n",
        "        t_class_id = torch.tensor(class_id)\n",
        "        return {'img': t_img, 'label': t_class_id}"
      ],
      "metadata": {
        "id": "fXRTxp6UwLby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_cats_path = \"/content/gdrive/My Drive/Colab Notebooks/dataset/train/Cats/\"\n",
        "train_dogs_path = \"/content/gdrive/My Drive/Colab Notebooks/dataset/train/Dogs/\"\n",
        "test_cats_path = \"/content/gdrive/My Drive/Colab Notebooks/dataset/test/Cats/\"\n",
        "test_dogs_path = \"/content/gdrive/My Drive/Colab Notebooks/dataset/test/Dogs/\"\n",
        "\n",
        "train_ds_catsdogs = Dataset2class(train_dogs_path, train_cats_path)\n",
        "test_ds_catsdogs = Dataset2class(test_dogs_path, test_cats_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "sR_1mZhl0Q_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_ds_catsdogs, shuffle=True, drop_last=True,\n",
        "    batch_size=batch_size, num_workers=0)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_ds_catsdogs, shuffle=True, drop_last=False,\n",
        "    batch_size=batch_size, num_workers=0)"
      ],
      "metadata": {
        "id": "qFS1DbkUwVrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tv.models.resnet34(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # Modify the final layer to match our number of classes\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "u9i79lG60Sz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06283eb-8f02-457d-bb81-c99d4256455e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:01<00:00, 82.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch in tqdm(train_loader):\n",
        "        inputs, labels = batch['img'].to(device), batch['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Validation function\n",
        "def validate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader):\n",
        "            inputs, labels = batch['img'].to(device), batch['label'].to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(test_loader)\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"cats_dogs_resnet34.pth\")\n",
        "\n",
        "# Testing loop\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "# Load the trained model for testing\n",
        "model.load_state_dict(torch.load(\"cats_dogs_resnet34.pth\"))\n",
        "\n",
        "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
        "test_losses.append(test_loss)\n",
        "test_accuracies.append(test_acc)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "CcWNEkftxUFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7c5abe-0d09-477f-8941-bbe617cb37ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 593/593 [39:48<00:00,  4.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Train Loss: 0.5367, Train Acc: 0.7484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 593/593 [11:31<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10\n",
            "Train Loss: 0.3884, Train Acc: 0.8294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 593/593 [11:25<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10\n",
            "Train Loss: 0.3849, Train Acc: 0.8300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 593/593 [11:20<00:00,  1.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10\n",
            "Train Loss: 0.3773, Train Acc: 0.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 593/593 [11:30<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10\n",
            "Train Loss: 0.2693, Train Acc: 0.8883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 593/593 [11:25<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10\n",
            "Train Loss: 0.2683, Train Acc: 0.8938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 376/593 [07:10<03:57,  1.09s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w4J9iio6lHMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2AefhejlkBj9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}